{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d51376f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61821b20",
   "metadata": {},
   "source": [
    "### Basic Neural Network using PyTorch\n",
    "\n",
    "\n",
    "###### X --> Input\n",
    "\n",
    "###### Wx --> Weights\n",
    "\n",
    "###### b --> Bias\n",
    "\n",
    "###### Y --> Output\n",
    "\n",
    "###### A --> Activation Function (Sigmoid,ReLU,Tanh)\n",
    "\n",
    "###### Z = WX + b\n",
    "\n",
    "###### Z` = Activation(Z)\n",
    "\n",
    "###### Y = W2.Z` + b2\n",
    "\n",
    "\n",
    "- Loss Function: MSE, Cross Entropy\n",
    "- Backpropagation: Gradient Descent, Adam, RMSProp\n",
    "- Optimizer: SGD, Adam, RMSProp\n",
    " \n",
    "\n",
    "\n",
    "### Components of Pytorch\n",
    "\n",
    "- Base class for defining cutom models is `torch.nn.Module`\n",
    "- Layers are defined in `__init__` method\n",
    "- Forward pass is defined in `forward` method\n",
    "- Loss functions are defined in `torch.nn` module\n",
    "- Optimizers are defined in `torch.optim` module\n",
    "- Data loading and preprocessing is done using `torch.utils.data` module\n",
    "- Fully connected layer is defined using `torch.nn.Linear`\n",
    "- Activation functions are defined in `torch.nn.ReLU` module \n",
    "- Optimizers are defined in `torch.optim` module\n",
    "- Loss functions are defined in `torch.nn.CrossEntropyLoss` module\n",
    "- Loads data in batches using `torch.utils.data.DataLoader` module\n",
    "\n",
    "\n",
    "### Different ways to define a model in Pytorch\n",
    "\n",
    "1. Functional: Flexable, harder to interpret\n",
    "2. Sequential: Easy to interpret, less flexable\n",
    "3. Custom: Most flexable, harder to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735aaa1",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eaeceb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "   def __init__(self,input_size,hidden_size,output_size):\n",
    "      super(SimpleNN,self).__init__()\n",
    "       \n",
    "      self.fullyConnectedLayer_1 = nn.Linear(input_size,hidden_size)\n",
    "      self.relu = nn.ReLU()\n",
    "      self.fullyConnnectedLayer_2 = nn.Linear(hidden_size,output_size)\n",
    "       \n",
    "       \n",
    "   def forward(self,x):\n",
    "      x = self.fullyConnectedLayer_1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.fullyConnnectedLayer_2(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebcc3d",
   "metadata": {},
   "source": [
    "### Sequential API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0056b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNNSequential(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa27bcf6",
   "metadata": {},
   "source": [
    "### Training the neural network using Functional API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fullyConnectedLayer_1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fullyConnnectedLayer_2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_func = SimpleNN(input_size=4, hidden_size=8,output_size=3)\n",
    "print(model_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c261988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1389, -0.0879, -0.3221, -1.3051],\n",
      "        [-2.1830,  0.5533,  0.9134,  0.4570],\n",
      "        [-0.6909,  2.3382,  1.7872,  0.0981],\n",
      "        [ 0.6401, -0.2904,  1.4872,  0.7067],\n",
      "        [-3.2414,  1.7718,  0.7386,  1.2536],\n",
      "        [-1.1780,  0.8628,  0.0609, -1.2035],\n",
      "        [-0.7195,  0.9851,  1.1702,  0.6910],\n",
      "        [-1.0075,  0.7824, -0.0161,  0.6443],\n",
      "        [ 0.6016, -0.7004,  0.1041, -0.1825],\n",
      "        [ 0.5777, -0.7019, -0.9470,  0.3431]])\n",
      "tensor([1, 2, 1, 2, 0, 2, 0, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(10,4) # 10 samples, 4 features\n",
    "Y = torch.randint(0,3,(10,))\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # includes the advance version of sigmax function\n",
    "optimizer = optim.Adam(model_func.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]/300 , Loss : 0.9478\n",
      "Epoch [20]/300 , Loss : 0.8220\n",
      "Epoch [30]/300 , Loss : 0.6997\n",
      "Epoch [40]/300 , Loss : 0.5830\n",
      "Epoch [50]/300 , Loss : 0.4780\n",
      "Epoch [60]/300 , Loss : 0.3907\n",
      "Epoch [70]/300 , Loss : 0.3177\n",
      "Epoch [80]/300 , Loss : 0.2569\n",
      "Epoch [90]/300 , Loss : 0.2048\n",
      "Epoch [100]/300 , Loss : 0.1623\n",
      "Epoch [110]/300 , Loss : 0.1285\n",
      "Epoch [120]/300 , Loss : 0.1022\n",
      "Epoch [130]/300 , Loss : 0.0821\n",
      "Epoch [140]/300 , Loss : 0.0670\n",
      "Epoch [150]/300 , Loss : 0.0553\n",
      "Epoch [160]/300 , Loss : 0.0464\n",
      "Epoch [170]/300 , Loss : 0.0395\n",
      "Epoch [180]/300 , Loss : 0.0339\n",
      "Epoch [190]/300 , Loss : 0.0295\n",
      "Epoch [200]/300 , Loss : 0.0258\n",
      "Epoch [210]/300 , Loss : 0.0229\n",
      "Epoch [220]/300 , Loss : 0.0204\n",
      "Epoch [230]/300 , Loss : 0.0183\n",
      "Epoch [240]/300 , Loss : 0.0165\n",
      "Epoch [250]/300 , Loss : 0.0150\n",
      "Epoch [260]/300 , Loss : 0.0137\n",
      "Epoch [270]/300 , Loss : 0.0125\n",
      "Epoch [280]/300 , Loss : 0.0115\n",
      "Epoch [290]/300 , Loss : 0.0106\n",
      "Epoch [300]/300 , Loss : 0.0098\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epoch = 300\n",
    "for e in range(epoch):\n",
    "   optimizer.zero_grad() # Clear all the gradients\n",
    "   outputs = model_func(X) # Passing inputs\n",
    "   loss = criterion(outputs,Y)\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "   \n",
    "   if(e+1) % 10 == 0:\n",
    "      print(f\"Epoch [{e+1}]/{epoch} , Loss : {loss.item() :.4f}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43a6bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f404b46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c600cb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e0ea99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357d767f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
