{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51376f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61821b20",
   "metadata": {},
   "source": [
    "### Basic Neural Network using PyTorch\n",
    "\n",
    "\n",
    "###### X --> Input\n",
    "\n",
    "###### Wx --> Weights\n",
    "\n",
    "###### b --> Bias\n",
    "\n",
    "###### Y --> Output\n",
    "\n",
    "###### A --> Activation Function (Sigmoid,ReLU,Tanh)\n",
    "\n",
    "###### Z = WX + b\n",
    "\n",
    "###### Z` = Activation(Z)\n",
    "\n",
    "###### Y = W2.Z` + b2\n",
    "\n",
    "\n",
    "- Loss Function: MSE, Cross Entropy\n",
    "- Backpropagation: Gradient Descent, Adam, RMSProp\n",
    "- Optimizer: SGD, Adam, RMSProp\n",
    " \n",
    "\n",
    "\n",
    "### Components of Pytorch\n",
    "\n",
    "- Base class for defining cutom models is `torch.nn.Module`\n",
    "- Layers are defined in `__init__` method\n",
    "- Forward pass is defined in `forward` method\n",
    "- Loss functions are defined in `torch.nn` module\n",
    "- Optimizers are defined in `torch.optim` module\n",
    "- Data loading and preprocessing is done using `torch.utils.data` module\n",
    "- Fully connected layer is defined using `torch.nn.Linear`\n",
    "- Activation functions are defined in `torch.nn.ReLU` module \n",
    "- Optimizers are defined in `torch.optim` module\n",
    "- Loss functions are defined in `torch.nn.CrossEntropyLoss` module\n",
    "- Loads data in batches using `torch.utils.data.DataLoader` module\n",
    "\n",
    "\n",
    "### Different ways to define a model in Pytorch\n",
    "\n",
    "1. Functional: Flexable, harder to interpret\n",
    "2. Sequential: Easy to interpret, less flexable\n",
    "3. Custom: Most flexable, harder to interpret"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8735aaa1",
   "metadata": {},
   "source": [
    "### Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eaeceb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "   def __init__(self,input_size,hidden_size,output_size):\n",
    "      super(SimpleNN,self).__init__()\n",
    "       \n",
    "      self.fullyConnectedLayer_1 = nn.Linear(input_size,hidden_size)\n",
    "      self.relu = nn.ReLU()\n",
    "      self.fullyConnnectedLayer_2 = nn.Linear(hidden_size,output_size)\n",
    "       \n",
    "       \n",
    "   def forward(self,x):\n",
    "      x = self.fullyConnectedLayer_1(x)\n",
    "      x = self.relu(x)\n",
    "      x = self.fullyConnnectedLayer_2(x)\n",
    "      return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ebcc3d",
   "metadata": {},
   "source": [
    "### Sequential API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0056b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNNSequential(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, hidden_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size, output_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa27bcf6",
   "metadata": {},
   "source": [
    "### Training the neural network using Functional API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (fullyConnectedLayer_1): Linear(in_features=4, out_features=8, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fullyConnnectedLayer_2): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_func = SimpleNN(input_size=4, hidden_size=8,output_size=3)\n",
    "print(model_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c261988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1389, -0.0879, -0.3221, -1.3051],\n",
      "        [-2.1830,  0.5533,  0.9134,  0.4570],\n",
      "        [-0.6909,  2.3382,  1.7872,  0.0981],\n",
      "        [ 0.6401, -0.2904,  1.4872,  0.7067],\n",
      "        [-3.2414,  1.7718,  0.7386,  1.2536],\n",
      "        [-1.1780,  0.8628,  0.0609, -1.2035],\n",
      "        [-0.7195,  0.9851,  1.1702,  0.6910],\n",
      "        [-1.0075,  0.7824, -0.0161,  0.6443],\n",
      "        [ 0.6016, -0.7004,  0.1041, -0.1825],\n",
      "        [ 0.5777, -0.7019, -0.9470,  0.3431]])\n",
      "tensor([1, 2, 1, 2, 0, 2, 0, 2, 2, 0])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(10,4) # 10 samples, 4 features\n",
    "Y = torch.randint(0,3,(10,))\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # includes the advance version of sigmax function\n",
    "optimizer = optim.Adam(model_func.parameters(),lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10]/300 , Loss : 0.9478\n",
      "Epoch [20]/300 , Loss : 0.8220\n",
      "Epoch [30]/300 , Loss : 0.6997\n",
      "Epoch [40]/300 , Loss : 0.5830\n",
      "Epoch [50]/300 , Loss : 0.4780\n",
      "Epoch [60]/300 , Loss : 0.3907\n",
      "Epoch [70]/300 , Loss : 0.3177\n",
      "Epoch [80]/300 , Loss : 0.2569\n",
      "Epoch [90]/300 , Loss : 0.2048\n",
      "Epoch [100]/300 , Loss : 0.1623\n",
      "Epoch [110]/300 , Loss : 0.1285\n",
      "Epoch [120]/300 , Loss : 0.1022\n",
      "Epoch [130]/300 , Loss : 0.0821\n",
      "Epoch [140]/300 , Loss : 0.0670\n",
      "Epoch [150]/300 , Loss : 0.0553\n",
      "Epoch [160]/300 , Loss : 0.0464\n",
      "Epoch [170]/300 , Loss : 0.0395\n",
      "Epoch [180]/300 , Loss : 0.0339\n",
      "Epoch [190]/300 , Loss : 0.0295\n",
      "Epoch [200]/300 , Loss : 0.0258\n",
      "Epoch [210]/300 , Loss : 0.0229\n",
      "Epoch [220]/300 , Loss : 0.0204\n",
      "Epoch [230]/300 , Loss : 0.0183\n",
      "Epoch [240]/300 , Loss : 0.0165\n",
      "Epoch [250]/300 , Loss : 0.0150\n",
      "Epoch [260]/300 , Loss : 0.0137\n",
      "Epoch [270]/300 , Loss : 0.0125\n",
      "Epoch [280]/300 , Loss : 0.0115\n",
      "Epoch [290]/300 , Loss : 0.0106\n",
      "Epoch [300]/300 , Loss : 0.0098\n"
     ]
    }
   ],
   "source": [
    "# Training Loop\n",
    "epoch = 300\n",
    "for e in range(epoch):\n",
    "   optimizer.zero_grad() # Clear all the gradients\n",
    "   outputs = model_func(X) # Passing inputs\n",
    "   loss = criterion(outputs,Y)\n",
    "   loss.backward()\n",
    "   optimizer.step()\n",
    "   \n",
    "   if(e+1) % 10 == 0:\n",
    "      print(f\"Epoch [{e+1}]/{epoch} , Loss : {loss.item() :.4f}\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b542f8de",
   "metadata": {},
   "source": [
    "#### <b><U>Linear Regression Model using Pytorch Components\n",
    " <U> </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a43a6bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.13-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (25.0)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (2.32.4)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (from kagglehub) (4.66.2)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2025.7.9)\n",
      "Downloading kagglehub-0.3.13-py3-none-any.whl (68 kB)\n",
      "Installing collected packages: kagglehub\n",
      "Successfully installed kagglehub-0.3.13\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f404b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded dataset path: /home/codespace/.cache/kagglehub/datasets/mirichoi0218/insurance/versions/1\n",
      "Dataset copied to: ./data/insurance\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Download dataset (cached location by kagglehub)\n",
    "path = kagglehub.dataset_download(\"mirichoi0218/insurance\")\n",
    "print(f\"Downloaded dataset path: {path}\")\n",
    "\n",
    "# Define your custom target directory\n",
    "target_dir = \"./data/insurance\"\n",
    "\n",
    "# Make sure the directory exists\n",
    "os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# Copy all files from kagglehub cache to your custom directory\n",
    "for file_name in os.listdir(path):\n",
    "    src = os.path.join(path, file_name)\n",
    "    dst = os.path.join(target_dir, file_name)\n",
    "    shutil.copy2(src, dst)  # copy2 preserves metadata\n",
    "\n",
    "print(f\"Dataset copied to: {target_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c600cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d5e0ea99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/insurance/insurance.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "357d767f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1338 entries, 0 to 1337\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       1338 non-null   int64  \n",
      " 1   sex       1338 non-null   object \n",
      " 2   bmi       1338 non-null   float64\n",
      " 3   children  1338 non-null   int64  \n",
      " 4   smoker    1338 non-null   object \n",
      " 5   region    1338 non-null   object \n",
      " 6   charges   1338 non-null   float64\n",
      "dtypes: float64(2), int64(2), object(3)\n",
      "memory usage: 73.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "      <td>1338.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.207025</td>\n",
       "      <td>30.663397</td>\n",
       "      <td>1.094918</td>\n",
       "      <td>13270.422265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.049960</td>\n",
       "      <td>6.098187</td>\n",
       "      <td>1.205493</td>\n",
       "      <td>12110.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>15.960000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1121.873900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>26.296250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4740.287150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>30.400000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9382.033000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>51.000000</td>\n",
       "      <td>34.693750</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16639.912515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>53.130000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>63770.428010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age          bmi     children       charges\n",
       "count  1338.000000  1338.000000  1338.000000   1338.000000\n",
       "mean     39.207025    30.663397     1.094918  13270.422265\n",
       "std      14.049960     6.098187     1.205493  12110.011237\n",
       "min      18.000000    15.960000     0.000000   1121.873900\n",
       "25%      27.000000    26.296250     0.000000   4740.287150\n",
       "50%      39.000000    30.400000     1.000000   9382.033000\n",
       "75%      51.000000    34.693750     2.000000  16639.912515\n",
       "max      64.000000    53.130000     5.000000  63770.428010"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset before encoding\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d853801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode cetagorical variable\n",
    "label_encoder = {}\n",
    "for col in [\"sex\", \"smoker\", \"region\"]:\n",
    "    le = LabelEncoder()\n",
    "    train_df[col] = le.fit_transform(train_df[col])\n",
    "    test_df[col] = le.transform(test_df[col])\n",
    "    label_encoder[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9909b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target\n",
    "X_train = train_df.drop(columns=[\"charges\"])\n",
    "y_train = train_df[\"charges\"]\n",
    "\n",
    "X_test = test_df.drop(columns=[\"charges\"])\n",
    "y_test = test_df[\"charges\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c30b7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train :\n",
      "       age  sex    bmi  children  smoker  region\n",
      "560    46    0  19.95         2       0       1\n",
      "1285   47    0  24.32         0       0       0\n",
      "1142   52    0  24.86         0       0       2\n",
      "969    39    0  34.32         5       0       2\n",
      "486    54    0  21.47         3       0       1\n",
      "y_train :\n",
      " 560      9193.83850\n",
      "1285     8534.67180\n",
      "1142    27117.99378\n",
      "969      8596.82780\n",
      "486     12475.35130\n",
      "Name: charges, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train :\\n\",X_train.head())\n",
    "print(\"y_train :\\n\",y_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0badc2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a825aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da588d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train_tensor)\n",
    "print(y_train_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c957e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test_tensor)\n",
    "print(X_test_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea671a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neural network model\n",
    "\n",
    "\n",
    "class SimpleNNRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNNRegressionModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0130402",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c44a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X_train_tensor.shape[1]\n",
    "model = SimpleNNRegressionModel(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95605af",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085bd77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optmiser\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimiser = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd0cfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "epochs = 30000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimiser.zero_grad()\n",
    "    predictions = model(X_train_tensor)\n",
    "    loss = criterion(predictions, y_train_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    optimiser.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}], Loss : {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4963c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation\n",
    "\n",
    "model.eval()\n",
    "y_pred = model(X_test_tensor).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394e3693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "y_test_numpy = y_test_tensor.numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "mse = mean_squared_error(y_test_numpy, y_pred)\n",
    "rmse = mse**0.5\n",
    "mae = mean_absolute_error(y_test_numpy, y_pred)\n",
    "r2 = r2_score(y_test_numpy, y_pred)\n",
    "\n",
    "print(f\"MSE : {mse}\")\n",
    "print(f\"RMSE : {rmse}\")\n",
    "print(f\"MAE : {mae}\")\n",
    "print(f\"R2-Score : {r2}\")\n",
    "\n",
    "# 0 --> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec40466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_charges(age, sex, bmi, children, smoker, region):\n",
    "    input_data = pd.DataFrame(\n",
    "        [[age, sex, bmi, children, smoker, region]],\n",
    "        columns=[\"age\", \"sex\", \"bmi\", \"children\", \"smoker\", \"region\"],\n",
    "    )\n",
    "\n",
    "    for col in [\"sex\", \"smoker\", \"region\"]:\n",
    "        input_data[col] = label_encoder[col].transform(input_data[col])\n",
    "    input_data = scaler.transform(input_data)\n",
    "    input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "    predicted_charge = model(input_tensor).item()\n",
    "    return predicted_charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9799d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = predict_charges(50, \"female\", 27.9, 0, \"yes\", \"southwest\")\n",
    "print(f\"Predicted insurance charge: ${predicted:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5564af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cffbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24560853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4014686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14f0e9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a5c32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd1d483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332e4502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a9192",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb425c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2319652b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23775b57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af46a023",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9024214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4aa9dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf3cff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741b396c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5614cbf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5984a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c201ff86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a8a17d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec70f90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cac080",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f0b583",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f407622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a8bf0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8dbf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bda67f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf44cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7083ea04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bda399",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86208a20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3ff49c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ee4ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
